{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dcecf7",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/shriharijhawar13/cnn-model-for-sign-language-mnist-dataset#CNN-Model-creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ad658",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68621032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(training_data.isna().sum()))\n",
    "print(np.sum(test_data.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.drop(labels = [\"label\"],axis = 1) \n",
    "Y_train = training_data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(labels = [\"label\"],axis = 1)\n",
    "Y_test = test_data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdf295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train / 255.0\n",
    "\n",
    "# X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a871288",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(Y_train.shape)\n",
    "display(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ad078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(x=Y_test, data = Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904786eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(x=Y_train, data = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c94268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "reg = model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acf620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_score,f1_score\n",
    "\n",
    "# precision = precision_score(Y_test,Y_pred)\n",
    "# f1_score = f1_score(Y_test,Y_pred)\n",
    "# tp,fp,fn,tn=cm.ravel()\n",
    "# sensibilite = tp/(tp+fn)\n",
    "# specificite = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_raw_LR = pd.DataFrame.from_dict(report)\n",
    "score_classification_report_raw_LR=classification_report_raw_LR['macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# creating a standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fitting independent data to the model\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "reg = model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5492efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ff57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_normalize_LR = pd.DataFrame.from_dict(report)\n",
    "score_classification_report_normalize_LR=classification_report_normalize_LR['macro avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089a4cf",
   "metadata": {},
   "source": [
    "**Normaliser permet d'avoir de meilleurs scores et de converger**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7db21",
   "metadata": {},
   "source": [
    "**Utiliser Gaussian NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "reg = model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)\n",
    "\n",
    "# changer la taille de la figure en utilisant la méthode set_size_inches\n",
    "fig.set_size_inches(15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ebe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_NB = pd.DataFrame.from_dict(report)\n",
    "score_classification_report_NB=classification_report_NB['macro avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8439dc",
   "metadata": {},
   "source": [
    "**Utiliser le decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0272e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# créer un modèle d'arbres de décision\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# entraîner le modèle en utilisant les données d'entraînement\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# prédire des labels pour les données de test\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f328f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d72ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_DTC = pd.DataFrame.from_dict(report)\n",
    "score_classification_report_DTC=classification_report_DTC['macro avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da827db9",
   "metadata": {},
   "source": [
    "**Random Forrest Classfiier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "reg = model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_RFC = pd.DataFrame.from_dict(report)\n",
    "classification_report_RFC\n",
    "score_classification_report_RFC=classification_report_RFC['macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "\n",
    "reg = model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fc966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d5d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_MLPC = pd.DataFrame.from_dict(report)\n",
    "classification_report_MLPC\n",
    "score_classification_report_MLPC=classification_report_MLPC['macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb314a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Normaliser les données d'entrée\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Définir le classificateur de réseau de neurones avec plusieurs couches cachées et fonctions d'activation différentes\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu')\n",
    "\n",
    "# Entraîner le modèle\n",
    "reg = model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Prédire les résultats sur les données de test\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Utiliser la méthode de bagging pour combiner plusieurs classificateurs de réseau de neurones\n",
    "bagging = BaggingClassifier(base_estimator=model, n_estimators=10)\n",
    "reg = bagging.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036a703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_BMLPC = pd.DataFrame.from_dict(report)\n",
    "classification_report_BMLPC\n",
    "score_classification_report_BMLPC=classification_report_BMLPC['macro avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638891d",
   "metadata": {},
   "source": [
    "**On cherche de meilleurs paramètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Normaliser les données d'entrée\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "parameters = {'hidden_layer_sizes': [(100, 100), (200, 200)],\n",
    "              'activation': ['relu', 'tanh'],\n",
    "              'alpha': [0.0001, 0.001]}\n",
    "\n",
    "# Utiliser la recherche en grille pour sélectionner les meilleurs hyperparamètres\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, cv=5)\n",
    "clf.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Imprimer les meilleurs hyperparamètres trouvés\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Normaliser les données d'entrée\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Définir le classificateur de réseau de neurones avec plusieurs couches cachées et fonctions d'activation différentes\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu',alpha=0.0001)\n",
    "\n",
    "# Entraîner le modèle\n",
    "reg = model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Prédire les résultats sur les données de test\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Utiliser la méthode de bagging pour combiner plusieurs classificateurs de réseau de neurones\n",
    "bagging = BaggingClassifier(base_estimator=model, n_estimators=10)\n",
    "reg = bagging.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecee882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "\n",
    "classification_report_BMLPC2 = pd.DataFrame.from_dict(report)\n",
    "classification_report_BMLPC2\n",
    "score_classification_report_BMLPC2=classification_report_BMLPC2['macro avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640d0d8",
   "metadata": {},
   "source": [
    "**Pas vraiment de meilleurs résultats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334bf39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In this step we are dividing the dataset in to X and Y training values\n",
    "# X contains information about the images \n",
    "# Y contains the correspondind label of that image\n",
    "# These two values will be used to train the model\n",
    "#creating our X for the training data\n",
    "x_train = training_data.drop(labels = [\"label\"],axis = 1) \n",
    "#creating our Y for the training data\n",
    "y_train = training_data[\"label\"]\n",
    "\n",
    "# In this step we are dividing the dataset in to X and Y test values\n",
    "# X contains information about the images\n",
    "# Y contains the correspondind label of that image\n",
    "# These two values will be used to test the model\n",
    "#creating our X for the training data\n",
    "x_test = test_data.drop(labels = [\"label\"],axis = 1) \n",
    "#creating our Y for the training data\n",
    "y_test = test_data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3568d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values.reshape(-1,28,28,1)\n",
    "x_test = x_test.values.reshape(-1,28,28,1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", padding='same',\n",
    "                  input_shape=[28, 28, 1]),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Dropout(.25),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Dropout(.25),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Dropout(.25),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Dropout(.25),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(.25),\n",
    "    layers.Dense(units=64, activation=\"relu\"),\n",
    "    layers.Dense(units=26, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433f426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 13\n",
    "batch_size = 128\n",
    "model_history = model.fit(x = x_train, y = y_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f8dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71278c7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(y_train.shape)\n",
    "display(y_test.shape)\n",
    "display(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2677d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les probabilités de classe en prédictions de classe\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31daeeb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "\n",
    "classification_report_CNN = pd.DataFrame.from_dict(report)\n",
    "classification_report_CNN\n",
    "score_classification_report_CNN=classification_report_CNN['macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa054809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un dictionnaire contenant toutes les variables globales\n",
    "global_vars = globals()\n",
    "\n",
    "# Filtrer les variables ayant un nom commençant par classification_report_\n",
    "classification_report_vars = [v for k, v in global_vars.items() if k.startswith('score_classification_')]\n",
    "\n",
    "# Imprimer les variables\n",
    "for var in classification_report_vars:\n",
    "    print(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe396ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
