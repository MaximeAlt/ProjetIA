{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d586a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Conv2D,Flatten,MaxPool2D,BatchNormalization,Activation,Dropout\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import csv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eefc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"landmark2.csv\",on_bad_lines='skip')\n",
    "X = df.drop(df.columns[0], axis = 1)\n",
    "y = df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63dedf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "len(y_train.unique())\n",
    "\n",
    "#y_train=keras.utils.to_categorical(y_train,27)\n",
    "#y_test=keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdabbf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 63)                4032      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8192      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613,723\n",
      "Trainable params: 613,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=63, input_shape=[63]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=27, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff513f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_A</th>\n",
       "      <th>target_B</th>\n",
       "      <th>target_C</th>\n",
       "      <th>target_D</th>\n",
       "      <th>target_E</th>\n",
       "      <th>target_F</th>\n",
       "      <th>target_G</th>\n",
       "      <th>target_H</th>\n",
       "      <th>target_I</th>\n",
       "      <th>target_K</th>\n",
       "      <th>...</th>\n",
       "      <th>target_S</th>\n",
       "      <th>target_T</th>\n",
       "      <th>target_U</th>\n",
       "      <th>target_V</th>\n",
       "      <th>target_W</th>\n",
       "      <th>target_X</th>\n",
       "      <th>target_Y</th>\n",
       "      <th>target_d</th>\n",
       "      <th>target_n</th>\n",
       "      <th>target_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_A  target_B  target_C  target_D  target_E  target_F  target_G  \\\n",
       "39877         0         0         0         0         0         0         0   \n",
       "5907          0         0         1         0         0         0         0   \n",
       "41920         0         0         0         0         0         0         0   \n",
       "\n",
       "       target_H  target_I  target_K  ...  target_S  target_T  target_U  \\\n",
       "39877         0         0         0  ...         0         0         0   \n",
       "5907          0         0         0  ...         0         0         0   \n",
       "41920         0         0         0  ...         0         0         0   \n",
       "\n",
       "       target_V  target_W  target_X  target_Y  target_d  target_n  target_s  \n",
       "39877         0         0         0         0         0         0         0  \n",
       "5907          0         0         0         0         0         0         0  \n",
       "41920         0         0         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded = pd.get_dummies(y_train, prefix='target')\n",
    "y_test_encoded = pd.get_dummies(y_test, prefix='target')\n",
    "y_train_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b69b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b7267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce489d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1155/1155 [==============================] - 12s 10ms/step - loss: 0.8893 - accuracy: 0.6951 - val_loss: 0.2218 - val_accuracy: 0.9333\n",
      "Epoch 2/5\n",
      "1155/1155 [==============================] - 10s 9ms/step - loss: 0.3125 - accuracy: 0.8980 - val_loss: 0.1535 - val_accuracy: 0.9485\n",
      "Epoch 3/5\n",
      "1155/1155 [==============================] - 10s 9ms/step - loss: 0.2640 - accuracy: 0.9168 - val_loss: 0.2787 - val_accuracy: 0.9047\n",
      "Epoch 4/5\n",
      "1155/1155 [==============================] - 11s 10ms/step - loss: 0.2214 - accuracy: 0.9316 - val_loss: 0.2314 - val_accuracy: 0.9251\n",
      "Epoch 5/5\n",
      "1155/1155 [==============================] - 10s 8ms/step - loss: 0.2180 - accuracy: 0.9353 - val_loss: 0.1206 - val_accuracy: 0.9694\n",
      "482/482 [==============================] - 2s 3ms/step\n",
      "Temps d'apprentissage : 53.314 s\n",
      "Temps d'apprentissage+prediction : 55.52 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model1.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    validation_split =0.2,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "stop1 = time.time()\n",
    "\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "stop2 = time.time()\n",
    "apprentissage_RFC = round(stop1-start,3)\n",
    "prediction_RFC = round(stop2-start,3)\n",
    "print(f\"Temps d'apprentissage : {apprentissage_RFC} s\")\n",
    "print(f\"Temps d'apprentissage+prediction : {prediction_RFC} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37b3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf369e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R', 17: 'S', 18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'}\n"
     ]
    }
   ],
   "source": [
    "liste_lettre=['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W',\"X\",\"Y\"]\n",
    "liste_nb = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "\n",
    "# Create a dictionary that maps letters to numbers\n",
    "key = {nb: lettre for nb, lettre in zip(liste_nb, liste_lettre)}\n",
    "\n",
    "# Print the dictionary\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f7a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_no, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            coord = []\n",
    "            for i in range(21):\n",
    "                \n",
    "                x = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].x\n",
    "                y = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].y\n",
    "                z = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].z\n",
    "                \n",
    "                coord.append([x, y, z])\n",
    "           \n",
    "            coord_rs = tf.reshape(coord, [1, -1])\n",
    "            live_pred = model1.predict(coord_rs)\n",
    "            live_pred = np.argmax(live_pred, axis=1)\n",
    "            display = key.get(int(live_pred))\n",
    "\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame,str(display),(50, 50),font,1,(0, 255, 255))\n",
    "#             cv2.putText(frame, text, (x, y), font, scale, color)\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
