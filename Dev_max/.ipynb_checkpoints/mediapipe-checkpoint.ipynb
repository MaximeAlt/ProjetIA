{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0198ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2b4820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "mp_model = mp_hands.Hands(\n",
    "static_image_mode=True, # only static images\n",
    "max_num_hands=2, # max 2 hands detection\n",
    "min_detection_confidence=0.5) # detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e18f78d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x: 0.5308032\n",
      "y: 0.58116275\n",
      "z: -1.4723457e-06\n",
      "]\n",
      "[x: 0.5036644\n",
      "y: 0.6166728\n",
      "z: -1.5487415e-06\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(image, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m mp_model\u001b[38;5;241m.\u001b[39mprocess(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hand_landmarks \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     15\u001b[0m     WRIST \u001b[38;5;241m=\u001b[39m [hand_landmarks\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mWRIST]]\n\u001b[0;32m     16\u001b[0m     THUMB_CMC \u001b[38;5;241m=\u001b[39m [hand_landmarks\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mTHUMB_CMC]]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "for label in alphabets:\n",
    "    dataset_directory_prefix = 'C:/Users/Maxime.ALTER/ProjetIA/ProjetIA/Dev_tib/photos_asl/asl_alphabet_train/asl_alphabet_train/'\n",
    "    for dirname, _, filenames in os.walk(dataset_directory_prefix + label):\n",
    "        for filename in filenames:\n",
    "            pathname = os.path.join(dirname, filename)\n",
    "            \n",
    "            image = cv2.imread(pathname)\n",
    "            image = cv2.flip(image, 1)\n",
    "            results = mp_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                WRIST = [hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]]\n",
    "                THUMB_CMC = [hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC]]\n",
    "                print(WRIST)\n",
    "              # we can get points using mp_hands\n",
    "              #print(f'Ring finger tip coordinates: (',\n",
    "              #  f'{hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]},'\n",
    "              #  f'{hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]}'\n",
    "              #  )\n",
    "            #\n",
    "           \n",
    "            ## Écrire les valeurs des pixels dans un fichier CSV\n",
    "            #with open('C:\\Users\\Maxime.ALTER\\ProjetIA\\ProjetIA\\Dev_max\\landmark.csv', 'w', newline='') as csvfile:\n",
    "            #    writer = csv.writer(csvfile)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "## Écrire les valeurs des pixels dans un fichier CSV\n",
    "#with open('mon_image.csv', 'w', newline='') as csvfile:\n",
    "#    writer = csv.writer(csvfile)\n",
    "#\n",
    "#    # Créer une liste contenant les valeurs de chaque pixel\n",
    "#    pixel_values = [pixels[x, y] for x in range(new_width) for y in range(new_height)]\n",
    "#\n",
    "#    # Écrire les valeurs des pixels dans une seule ligne du fichier CSV\n",
    "#    writer.writerow(pixel_values)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "332d71dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n"
     ]
    }
   ],
   "source": [
    "alphabets = list(\"ABCDEFGHIKLMNOPQRSTUVWXY\")\n",
    "print(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1be69842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_dataset = []\n",
    "#\n",
    "#for label in alphabets:\n",
    "#    dataset_directory_prefix = 'C:/Users/Maxime.ALTER/ProjetIA/ProjetIA/Dev_tib/photos_asl/asl_alphabet_train/asl_alphabet_train/'\n",
    "#    for dirname, _, filenames in os.walk(dataset_directory_prefix + label):\n",
    "#        for filename in filenames:\n",
    "#            pathname = os.path.join(dirname, filename)\n",
    "#\n",
    "#            with mp_hands.Hands(\n",
    "#                static_image_mode=True,\n",
    "#                max_num_hands=1,\n",
    "#                min_detection_confidence=0.3\n",
    "#            ) as hands:\n",
    "#\n",
    "#                image = cv2.flip(cv2.imread(pathname), 1)\n",
    "#                result = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#\n",
    "#                landmark_vertices_xyz = []\n",
    "#                if not result.multi_hand_landmarks:\n",
    "#                    continue\n",
    "#\n",
    "#                for l in result.multi_hand_landmarks[0].landmark:\n",
    "#                    landmark_vertices_xyz.append(l.x)\n",
    "#                    landmark_vertices_xyz.append(l.y)\n",
    "#                    landmark_vertices_xyz.append(l.z)\n",
    "#\n",
    "#                temp_dataset.append((*landmark_vertices_xyz, label))\n",
    "#                \n",
    "#    print(f'imported: {label}')\n",
    "#        \n",
    "#landmark_vertices_xyz_label = []\n",
    "#for idx in range(21):\n",
    "#    for char in list('xyz'):\n",
    "#        vertex_label = char+str(idx)\n",
    "#        landmark_vertices_xyz_label.append(vertex_label)\n",
    "#            \n",
    "#print(*landmark_vertices_xyz_label)\n",
    "#        \n",
    "#dataset = pd.DataFrame(temp_dataset, columns=[*landmark_vertices_xyz_label, 'target'])\n",
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = []\n",
    "pathname = \n",
    "\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.3) as hands:\n",
    "    image = cv2.flip(cv2.imread(pathname), 1)\n",
    "    result = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RG\n",
    "    landmark_vertices_xyz = []\n",
    "    if not result.multi_hand_landmarks:\n",
    "        continue\n",
    "    for l in result.multi_hand_landmarks[0].landmark:\n",
    "        landmark_vertices_xyz.append(l.x)\n",
    "        landmark_vertices_xyz.append(l.y)\n",
    "        landmark_vertices_xyz.append(l\n",
    "    temp_dataset.append((*landmark_vertices_xyz, label))\n",
    "                \n",
    "    print(f'imported: {label}')\n",
    "        \n",
    "landmark_vertices_xyz_label = []\n",
    "for idx in range(21):\n",
    "    for char in list('xyz'):\n",
    "        vertex_label = char+str(idx)\n",
    "        landmark_vertices_xyz_label.append(vertex_label)\n",
    "            \n",
    "print(*landmark_vertices_xyz_label)\n",
    "        \n",
    "dataset = pd.DataFrame(temp_dataset, columns=[*landmark_vertices_xyz_label, 'target'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop(['target'],axis=1).values\n",
    "y = dataset['target'].values\n",
    "\n",
    "# Choose your test size to split between training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
