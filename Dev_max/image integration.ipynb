{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa559a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Conv2D,Flatten,MaxPool2D,BatchNormalization,Activation,Dropout\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import csv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"landmark2.csv\",on_bad_lines='skip')\n",
    "X = df.drop(df.columns[0], axis = 1)\n",
    "y = df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67da764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "len(y_train.unique())\n",
    "\n",
    "#y_train=keras.utils.to_categorical(y_train,27)\n",
    "#y_test=keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08261fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 63)                4032      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8192      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613,723\n",
      "Trainable params: 613,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=63, input_shape=[63]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=27, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc450e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_A</th>\n",
       "      <th>target_B</th>\n",
       "      <th>target_C</th>\n",
       "      <th>target_D</th>\n",
       "      <th>target_E</th>\n",
       "      <th>target_F</th>\n",
       "      <th>target_G</th>\n",
       "      <th>target_H</th>\n",
       "      <th>target_I</th>\n",
       "      <th>target_K</th>\n",
       "      <th>...</th>\n",
       "      <th>target_S</th>\n",
       "      <th>target_T</th>\n",
       "      <th>target_U</th>\n",
       "      <th>target_V</th>\n",
       "      <th>target_W</th>\n",
       "      <th>target_X</th>\n",
       "      <th>target_Y</th>\n",
       "      <th>target_d</th>\n",
       "      <th>target_n</th>\n",
       "      <th>target_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_A  target_B  target_C  target_D  target_E  target_F  target_G  \\\n",
       "39877         0         0         0         0         0         0         0   \n",
       "5907          0         0         1         0         0         0         0   \n",
       "41920         0         0         0         0         0         0         0   \n",
       "\n",
       "       target_H  target_I  target_K  ...  target_S  target_T  target_U  \\\n",
       "39877         0         0         0  ...         0         0         0   \n",
       "5907          0         0         0  ...         0         0         0   \n",
       "41920         0         0         0  ...         0         0         0   \n",
       "\n",
       "       target_V  target_W  target_X  target_Y  target_d  target_n  target_s  \n",
       "39877         0         0         0         0         0         0         0  \n",
       "5907          0         0         0         0         0         0         0  \n",
       "41920         0         0         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded = pd.get_dummies(y_train, prefix='target')\n",
    "y_test_encoded = pd.get_dummies(y_test, prefix='target')\n",
    "y_train_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28fba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3987155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34347dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1155/1155 [==============================] - 9s 6ms/step - loss: 0.9859 - accuracy: 0.6551 - val_loss: 0.2756 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "1155/1155 [==============================] - 8s 7ms/step - loss: 0.3714 - accuracy: 0.8720 - val_loss: 0.3262 - val_accuracy: 0.8732\n",
      "Epoch 3/5\n",
      "1155/1155 [==============================] - 9s 8ms/step - loss: 0.2828 - accuracy: 0.9086 - val_loss: 0.1682 - val_accuracy: 0.9363\n",
      "Epoch 4/5\n",
      "1155/1155 [==============================] - 9s 8ms/step - loss: 0.2506 - accuracy: 0.9208 - val_loss: 0.1247 - val_accuracy: 0.9688\n",
      "Epoch 5/5\n",
      "1155/1155 [==============================] - 9s 7ms/step - loss: 0.2313 - accuracy: 0.9311 - val_loss: 0.1287 - val_accuracy: 0.9660\n",
      "482/482 [==============================] - 1s 2ms/step\n",
      "Temps d'apprentissage : 42.973 s\n",
      "Temps d'apprentissage+prediction : 44.451 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model1.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    validation_split =0.2,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "stop1 = time.time()\n",
    "\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "stop2 = time.time()\n",
    "apprentissage_RFC = round(stop1-start,3)\n",
    "prediction_RFC = round(stop2-start,3)\n",
    "print(f\"Temps d'apprentissage : {apprentissage_RFC} s\")\n",
    "print(f\"Temps d'apprentissage+prediction : {prediction_RFC} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae82f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48c6b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R', 17: 'S', 18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'}\n"
     ]
    }
   ],
   "source": [
    "liste_lettre=['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W',\"X\",\"Y\"]\n",
    "liste_nb = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "\n",
    "# Create a dictionary that maps letters to numbers\n",
    "key = {nb: lettre for nb, lettre in zip(liste_nb, liste_lettre)}\n",
    "\n",
    "# Print the dictionary\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16634e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Ouvrir la camÃ©ra de l'ordinateur\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Prendre une photo\n",
    "ret, frame = camera.read()\n",
    "\n",
    "# Sauvegarder la photo\n",
    "cv2.imwrite('mon_image.jpg', frame)\n",
    "\n",
    "# Fermer la camÃ©ra\n",
    "camera.release()\n",
    "\n",
    "image = Image.open('mon_image.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcb1f41e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_hands\u001b[38;5;241m.\u001b[39mHands(\n\u001b[0;32m      4\u001b[0m     static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     max_num_hands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      6\u001b[0m     min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hands:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(IMAGE_FILES):\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# Read an image, flip it around y-axis for correct handedness output (see\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# above).\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Convert the BGR image to RGB before processing.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         results \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "# For static images:\n",
    "IMAGE_FILES = [image]\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "        # Print handedness and draw hand landmarks on the image.\n",
    "        print('Handedness:', results.multi_handedness)\n",
    "        if not results.multi_hand_landmarks:\n",
    "          continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        for hand_no, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            coord = []\n",
    "            for i in range(21):\n",
    "                \n",
    "                x = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].x\n",
    "                y = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].y\n",
    "                z = hand_landmarks.landmark[mp_hands.HandLandmark(i).value].z\n",
    "                coord.append([x, y, z])\n",
    "            coord_rs = tf.reshape(coord, [1, -1])\n",
    "            live_pred = model1.predict(cood_rs)\n",
    "            live_pred = np.argmax(live_pred, axis=1)\n",
    "            display = key.get(int(live_pred))\n",
    "            print(display)\n",
    "        \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "            cv2.imwrite(\n",
    "                '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "            # Draw hand world landmarks.\n",
    "            if not results.multi_hand_world_landmarks:\n",
    "              continue\n",
    "        for hand_world_landmarks in results.multi_hand_world_landmarks:\n",
    "          mp_drawing.plot_landmarks(\n",
    "            hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1eba3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "coord_rs = tf.reshape(coord, [1, -1])\n",
    "live_pred = model1.predict(coord_rs)\n",
    "live_pred = np.argmax(live_pred, axis=1)\n",
    "print(live_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
